\section{Binärcodierung}

% TODO Huffmann, Markov, etc\ldots


\subsection{Diskrete Quellen}

Bei den diskreten Quellen werden beliebige Zeichen der Quelle auf binäre
Codeworte ($CW$) abgebildet.

Günstig ist, wenn die mittlere Codewortlänge $\overline{n}$ möglichst klein ist.

Beispiele für $CW$:
\begin{itemize}
	\item ASCII: Block-Code mit fester Wortgrösse ($n$ = 8 Bit)
	\item Morsecode: Variable Wortgrösse ($n$ = 1\ldots 4 Bit)
\end{itemize}

Mittlere Codewortlänge:
\[
	\overline{n} = \sum_{i=1}^N p_i \cdot n_i~\left[\frac{\textrm{Bit}}{\textrm{Zeichen}}\right]
\]


\subsection{Präfixeigenschaft}
\label{sec:praefixeigenschaft}

Der Morsecode besitzt das Problem, dass er zwischen den einzelnen Zeichen eine
Pause bzw. ein Trennzeichen benötigt. Fehlt dieses Trennzeichen, so kann der
Empfänger nicht entscheiden, ob ein gültiges Zeichen oder nur ein
Zwischenschritt zu einem anderen gültigen Zeichen gesendet wurde.

Ein Code besitzt dann die Präfixeigenschaft, wenn alle Zeichen ausschliesslich
in den Blättern des Baumes codiert sind.  

Für jede Codierung mit Präfixeigenschaft gilt: Die Entropie $H$ ist stets
kleiner oder gleich gross wie die mittlere Codewortlänge $L$.

\[
	H(x) \le L(X)
\]

\begin{figure}[H]
	\fbox{%
		\begin{minipage}{.4\linewidth}
			\input{tikz/praefixeigenschaft}
		\end{minipage}
		\begin{minipage}{.6\linewidth}
			\begin{tabular}{@{}l l}
				A = 100 & p = 0.2 \\
				B = 1101 & p = 0.1 \\
				C = 1100 & p = 0.1 \\
				D = 111 & p = 0.2 \\
				E = 0 & p = 0.4 \\
			\end{tabular}\\\\

			\textit{CEBA}: 1100 / 0 / 1101 / 100 \\

			$L = 3 \cdot 0.2 + 4 \cdot 0.1 + 4 \cdot 0.1 + 3 \cdot 0.2 + 1 \cdot 0.4 = 2.4$

		\end{minipage}
	}
	\caption{Beispielcode mit Präfixeigenschaft}
\end{figure}


\subsection{Fehlerkorrektur}

Es gibt zwei Arten von Fehlerkorrektur: Bei der \textbf{Vorwärtskorrektur} wird
der Fehler nach Erhalt der Nachricht vom Empfänger selbstständig korrigiert, bei
der \textbf{Rückwärtskorrektur} wird bei Fehlern die Nachricht erneut
angefordert.


\subsection{Lineare Blockcodes}

Bei den Linearen Blockcodes werden Nachrichten in feste Blockgrössen $u$
aufgeteilt. Durch die Codierung wird jedem Block ein eindeutiges Codewort der
Länge $n$ zugewiesen.
Beispiel:
\[
	1010 \rightarrow 0011010
\]
Ein $(n,k)$-Blockcode bildet die $2^k$ möglichen Nachrichtenwörter bijektiv auf
$2^k$ $n$dimensionale Codewörter ab. Statt der $k$ Bits des Nachrichtenwortes
werden die $n$ Bits des Codewortes übertragen. Man spricht von einer Redundanten
Codierung mit der \textbf{Coderate} $R$:
\[
	R = \frac{k}{n}
\]
In einem \textbf{Systematischen Code} kann die Nachricht direkt aus dem Codewort
abgelesen werden.

\subsubsection{Hamming-Code}

Für jede natürliche Zahl $m \ge 3$ existiert ein $(n,k)$-Hamming-Code mit folgenden
fünf Eigenschaften:

\begin{center}
\begin{tabular}[H]{ll}
	\hline
	Codewortlänge & $n = 2^m - 1$ \\
	Nachrichtenstellen & $k = 2^m - 1 - m$ \\
	Kontrollstellen & $m = n - k$ \\
	Fehlerkorrekturvermögen & $t = 1, d_{min} = 3$ \\
	Perfekter Code & ja \\
	\hline
\end{tabular}
\end{center}

Die Konstruktion der Hamming-Codes erfolgt anhand der Prüfmatrix. Folgende Regel
liefern die Konstruktionsvorschrift:
\begin{itemize}
	\item Alle Spalten der Prüfmatrix müssen verschieden sein, damit Einzelfehler
		eindeutig erkannt werden können.
	\item Jede Zeile der Generatormatrix $\mtx{G}$ muss mindestens drei mal eine 1
		enthalten, um die minimale Hamming-Distanz $d_{min} = 3$ zu erfüllen. Daraus
		folgt, dass jede Zeile der Matrix $\mtx{P}$ (Prüfteil) mindestens zwei mal
		eine 1 enthalten muss. Die dritte 1 liefert die Einheitsmatrix $\mtx{I}$.
		Für die transponierte Matrix $\mtx{P}^T$ gilt entsprechend, dass jede Spalte
		mindestens zwei mal die 1 enthalten muss.
	\item Die Spalten der transponierten Matrix $\mtx{P}^T$ werden durch alle
		$m$-Tupel mit Hamming-Gewicht $w_H \ge 2$ gebildet.
\end{itemize}

\textbf{Beispiel} anhand des $(15,11)$-Hamming-Codes:

Prüfmatrix $\mtx{H}_{4x15}$:

\input{tikz/pruefmatrix}

Generatormatrix $\mtx{G}_{11x15}$:

\input{tikz/generatormatrix}
