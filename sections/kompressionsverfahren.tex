\section{Kompressionsverfahren}

Das Ziel der Kompression ist die Reduktion der Redundanz und das Entfernen der
Irrelevanz. Man unterscheidet drei Varianten:

\begin{itemize}
	\item Statische Verfahren\\
		- z.B. Huffman-Codierung für bekannte Daten (beispielsweise die Deutsche
		Sprache)\\
		- Blockdaten
	\item Adaptive Verfahren\\
		- z.B. Huffman-Codierung mit gemessener Häufigkeitsverteilung\\
		- Blockdaten
	\item Dynamische Verfahren\\
		- z.B. LZ77 (Lempel-Ziv)\\
		- Streamingdaten
\end{itemize}


\subsection{Huffman}

Das Prinzip hinter der Huffman-Codierung ist es, häufige Wörter mit möglichst
kurzen Codeworten zu codieren. Ein Beispiel dafür ist das Morse-Alphabet,
welches den häufig vorkommenden Buchstaben \textit{E} mit dem Zeichen \textit{.}
und den selten vorkommenden Buchstaben \textit{X} mit den vier Zeichen
\textit{-..-} codiert. (Der Morsecode besitzt jedoch keine Präfixeigenschaft,
siehe \autoref{sec:praefixeigenschaft} auf
Seite~\pageref{sec:praefixeigenschaft}.)

Die Huffman Codierung läuft folgendermassen ab:

\begin{itemize}
	\item \textit{Ordnen} -- Ordne die Zeichen nach fallenden
		Wahrscheinlichkeiten. Erstelle einen alleinstehenden Baum-Knoten für jedes
		Zeichen. Schreibe die Auftrittswahrscheinlichkeit an die Kante.
	\item \textit{Reduzieren} -- Kombiniere* die beiden Bäume mit den kleinsten
		Wahrscheinlichkeiten, indem sie Teilbäume einer neuen Wurzel werden.
		Schreibe die kombinierte Wahrscheinlichkeit an die Kante der neuen Wurzel.
		Ordne die Liste neu wie in Schritt 1 und fahre fort, bis alle Zeichen
		zusammengefasst sind.
	\item \textit{Codieren} -- Beginne bei der letzten Zusammenfassung. Ordne der
		Kante zum ersten Unterknoten eine $0$ und der Kante zum zweiten Unterknoten
		eine $1$ zu.

		Fahre sinngemäss fort, bis alle Zeichen codiert sind.
\end{itemize}

\textit{* Im Falle mehrerer Zeichen mit derselben Wahrscheinlichkeit werden die
Zeichen kombiniert, die am wenigsten bereits zusammengefasste Zeichen
beinhalten. Damit erreicht man bei gleicher mittlerer Codewortlänge eine in
der Übertragungstechnik günstigere, weil gleichmässigere Verteilung der
Codewortlängen.}

Für diskrete gedächtnislose Quellen liefert die Huffman Codierung mit variabler
Wortlänge immer einen optimalen Präfixcode $\rightarrow$ sie liefert die
kleinste mittlere Codewortlänge. Zudem ist ein solcher Code ohne Komma-Zeichen
zur Trennung der Codewörter eindeutig decodierbar.


\subsection{Lempel-Ziv}

Der LZ78 Algorithmus ist ein Dynamisches Verfahren zwecks Ausnutzung
wiederkehrender Muster. Es wird nicht der Code sondern die codierten Phrasen
übertragen und in einem Phrasenspeicher (``Wörterbuch'') gespeichert. Als
Phrasenspeicher wird ein ständig wachsender Baum erzeugt, mit den Knoten als
Referenzen. Treten die selben Phrasen wiederholt auf, wird nicht die Phrase
sondern nur der Knoten des Phrasenspeichers referenziert.

Funktionsweise:

\begin{enumerate}
	\item Die zu codierende Zeichenfolge wird in Teilfolgen aufgeteilt, welche
		alle verschieden sind.
	\item Bei den zu übertragenden Zeichen werden die Position im Baum und evtl.
		neue Zeichenfolgen angegeben. Beispiel: $(3,1)$ $\rightarrow$ Position 3 im
		Baum, neues Zeichen 1.
	\item Es wird ein Phrasenspeicher (Decoderbaum) aufgebaut, welcher bereits
		übertragene Zeichenfolgen speichert.
\end{enumerate}

Voraussetzung für gute Kompression ist, dass die Zeichenfolge viele
Regelmässigkeiten besitzt. Ansonsten kann es sein, dass der ``komprimierte
Code'' grösser als der Ursprüngliche ist.

Probleme:
\begin{itemize}
	\item Effizientes Suchen und Einfügen in den Baum
	\item Grösse des Baumes -- der Baum kann nur bis zu einer gewissen Grösse wachsen
\end{itemize}

Siehe \autoref{example:lempel-ziv} auf Seite~\pageref{example:lempel-ziv}
für ein Anwendungsbeispiel.
